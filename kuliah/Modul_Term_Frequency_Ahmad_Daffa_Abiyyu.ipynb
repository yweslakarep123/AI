{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing\n",
        "\n",
        "1. Tokenizing merupakan proses memecah dokumen menjadi kumpulan kata. Tokenization\n",
        "dapat dilakukan dengan menghilangkan tanda baca dan memisahkannya per spasi.\n",
        "Tahapan ini juga menghilangkan karakter-karakter tertentu seperti tanda baca dan mengubah semua token ke bentuk huruf kecil (lower case). Untuk melakukan tokenizing kita perlu melakukan hal sebagai berikut :"
      ],
      "metadata": {
        "id": "6y40CIDysWiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import math\n",
        "import string\n",
        "\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download resource yang dibutuhkan\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "text_str = '''\n",
        "Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19 untuk mencapai herd immunity di Indonesia sangat besar.\n",
        "Untuk itu, Pemerintah mengupayakan ketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.\n",
        "Dalam mendukung kebijakan penyediaan vaksin COVID-19 tersebut, sebagai\n",
        "Regulator Obat di Indonesia Badan POM melakukan pengawalan terhadap\n",
        "pemenuhan Khasiat, Keamanan dan Mutu obat agar masyarakat dapat\n",
        "mengakses Vaksin COVID-19 yang memenuhi standar dan persyaratan dan\n",
        "dalam waktu yang tepat dengan menerbitkan Izin Penggunaan\n",
        "Darurat/Emergency Use Authorization.\n",
        "Sebelumnya, Badan POM telah mengeluarkan Izin Penggunaan\n",
        "Darurat/Emergency Use Authorization (EUA) terhadap 7 produk vaksin\n",
        "COVID-19, yaitu Vaksin CoronaVac (Sinovac), Vaksin COVID-19 Bio Farma,\n",
        "Vaksin AstraZeneca, Vaksin Sinopharm, Vaksin Moderna, Vaksin Comirnaty\n",
        "(Pfizer and BioNTech), dan Vaksin Sputnik-V. Selasa (07/09), Badan POM\n",
        "kembali menerbitkan EUA bagi 2 (dua) produk vaksin COVID-19 yang baru,\n",
        "yaitu Janssen COVID-19 Vaccine dan Vaksin Convidecia.\n",
        "'''\n",
        "\n",
        "# Melakukan tokenisasi kalimat\n",
        "sentences = sent_tokenize(text_str)\n",
        "total_documents = len(sentences)\n",
        "\n",
        "# Menampilkan hasil tokenisasi\n",
        "print(sentences)\n",
        "print(\"Jumlah kalimat:\", len(sentences))\n",
        "#print(\"Jumlah dokumen:\", total_documents)\n"
      ],
      "metadata": {
        "id": "q2wWS133ssRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4bb608-db57-4f17-9c0a-926260c1b9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\nJumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19 untuk mencapai herd immunity di Indonesia sangat besar.', 'Untuk itu, Pemerintah mengupayakan ketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.', 'Dalam mendukung kebijakan penyediaan vaksin COVID-19 tersebut, sebagai\\nRegulator Obat di Indonesia Badan POM melakukan pengawalan terhadap\\npemenuhan Khasiat, Keamanan dan Mutu obat agar masyarakat dapat\\nmengakses Vaksin COVID-19 yang memenuhi standar dan persyaratan dan\\ndalam waktu yang tepat dengan menerbitkan Izin Penggunaan\\nDarurat/Emergency Use Authorization.', 'Sebelumnya, Badan POM telah mengeluarkan Izin Penggunaan\\nDarurat/Emergency Use Authorization (EUA) terhadap 7 produk vaksin\\nCOVID-19, yaitu Vaksin CoronaVac (Sinovac), Vaksin COVID-19 Bio Farma,\\nVaksin AstraZeneca, Vaksin Sinopharm, Vaksin Moderna, Vaksin Comirnaty\\n(Pfizer and BioNTech), dan Vaksin Sputnik-V. Selasa (07/09), Badan POM\\nkembali menerbitkan EUA bagi 2 (dua) produk vaksin COVID-19 yang baru,\\nyaitu Janssen COVID-19 Vaccine dan Vaksin Convidecia.']\n",
            "Jumlah kalimat: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency Matrix\n",
        "\n",
        "2. Membuat matrik frekuensi kata-kata dalam setiap kalimat. Dalam proses ini akan dilakukan perhitungan frekuensi kata dalam setiap kalimat. Lakukan perintah berikut ini :"
      ],
      "metadata": {
        "id": "mjezWxOCuQ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membuat matriks frekuensi\n",
        "nltk.download('stopwords')\n",
        "def create_frequency_matrix(sentences):\n",
        "    frequency_matrix = {}\n",
        "    stop_words = set(stopwords.words(\"indonesian\"))  # Gunakan stopwords bahasa Indonesia\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    for sent in sentences:\n",
        "        freq_table = {}\n",
        "        words = word_tokenize(sent)\n",
        "\n",
        "        for word in words:\n",
        "            word = word.lower()  # Konversi ke huruf kecil\n",
        "            word = ps.stem(word)  # Stemming\n",
        "\n",
        "            if word in stop_words:  # Hilangkan stopwords\n",
        "                continue\n",
        "\n",
        "            if word in freq_table:\n",
        "                freq_table[word] += 1\n",
        "            else:\n",
        "                freq_table[word] = 1\n",
        "\n",
        "        frequency_matrix[sent] = freq_table  # Simpan hasil dalam dictionary\n",
        "\n",
        "    return frequency_matrix\n",
        "\n",
        "# Contoh input teks\n",
        "text_str = '''Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\n",
        "untuk mencapai herd immunity di Indonesia sangat besar. Untuk itu, Pemerintah mengupayakan\n",
        "ketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.'''\n",
        "\n",
        "# Tokenisasi kalimat\n",
        "sentences = sent_tokenize(text_str)\n",
        "\n",
        "# Pembuatan matriks frekuensi\n",
        "freq_matrix = create_frequency_matrix(sentences)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(freq_matrix)"
      ],
      "metadata": {
        "id": "ToBcjqG7uu8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f90c07e-e9f2-4ac1-df83-49d5f9991a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\\nuntuk mencapai herd immunity di Indonesia sangat besar.': {'kebutuhan': 1, 'vaksin': 1, 'program': 1, 'vaksinasi': 1, 'penanganan': 1, 'pandemi': 1, 'covid-19': 1, 'mencapai': 1, 'herd': 1, 'immun': 1, 'indonesia': 1, '.': 1}, 'Untuk itu, Pemerintah mengupayakan\\nketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.': {',': 2, 'pemerintah': 1, 'mengupayakan': 1, 'ketersediaan': 1, 'vaksin': 1, 'sumber': 1, 'salah': 1, 'satunya': 1, 'kerja': 1, 'negara': 1, '.': 1}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequency\n",
        "\n",
        "3. Melakukan perhitungan TermFrequency dan membuatnya dalam bentuk matriks. Jika kita membandingkan hasil dari proses tiga ini dengan proses kedua maka kita dapat melihat bahwa kata-kata yang memiliki frekuensi yang sama memiliki skor TF yang serupa juga. Berikut ini perintahnya :"
      ],
      "metadata": {
        "id": "2SslzG7xxBSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membuat matriks Term Frequency (TF)\n",
        "def create_tf_matrix(freq_matrix):\n",
        "    tf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        tf_table = {}\n",
        "        count_words_in_sentence = len(f_table)  # Jumlah kata unik dalam kalimat\n",
        "\n",
        "        for word, count in f_table.items():\n",
        "            tf_table[word] = count / count_words_in_sentence  # Perhitungan TF\n",
        "\n",
        "        tf_matrix[sent] = tf_table  # Simpan hasil TF untuk setiap kalimat\n",
        "\n",
        "    return tf_matrix\n",
        "\n",
        "# Membuat TF matrix dari frequency matrix yang sudah dihitung sebelumnya\n",
        "tf_matrix = create_tf_matrix(freq_matrix)\n",
        "\n",
        "# Menampilkan hasil TF matrix\n",
        "print(tf_matrix)"
      ],
      "metadata": {
        "id": "Y5JIRY0uyQUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bd93d0-9e88-4a91-b0a7-857f29399ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\\nuntuk mencapai herd immunity di Indonesia sangat besar.': {'kebutuhan': 0.08333333333333333, 'vaksin': 0.08333333333333333, 'program': 0.08333333333333333, 'vaksinasi': 0.08333333333333333, 'penanganan': 0.08333333333333333, 'pandemi': 0.08333333333333333, 'covid-19': 0.08333333333333333, 'mencapai': 0.08333333333333333, 'herd': 0.08333333333333333, 'immun': 0.08333333333333333, 'indonesia': 0.08333333333333333, '.': 0.08333333333333333}, 'Untuk itu, Pemerintah mengupayakan\\nketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.': {',': 0.18181818181818182, 'pemerintah': 0.09090909090909091, 'mengupayakan': 0.09090909090909091, 'ketersediaan': 0.09090909090909091, 'vaksin': 0.09090909090909091, 'sumber': 0.09090909090909091, 'salah': 0.09090909090909091, 'satunya': 0.09090909090909091, 'kerja': 0.09090909090909091, 'negara': 0.09090909090909091, '.': 0.09090909090909091}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matriks IDF\n",
        "4. Dalam langkah ini, kita membuat sebuah tabel sederhana untuk membantu dalam menghitung matriks IDF. Proses ini akan digunakan untuk menghitung banyak kalimat yang mengandung sebuah kata dalam dokumen. Lakukan perintah berikut ini :"
      ],
      "metadata": {
        "id": "Q1QCsc8eyXJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_documents_per_words(freq_matrix):\n",
        "    word_per_doc_table = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        for word in f_table.keys():\n",
        "            word_per_doc_table[word] = word_per_doc_table.get(word, 0) + 1\n",
        "\n",
        "    return word_per_doc_table\n",
        "\n",
        "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
        "print(count_doc_per_words)\n"
      ],
      "metadata": {
        "id": "ATgiwp4JyhVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22314a2-55f6-4693-e944-541d8a6e2718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'kebutuhan': 1, 'vaksin': 2, 'program': 1, 'vaksinasi': 1, 'penanganan': 1, 'pandemi': 1, 'covid-19': 1, 'mencapai': 1, 'herd': 1, 'immun': 1, 'indonesia': 1, '.': 2, ',': 1, 'pemerintah': 1, 'mengupayakan': 1, 'ketersediaan': 1, 'sumber': 1, 'salah': 1, 'satunya': 1, 'kerja': 1, 'negara': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Menghitung IDF dan membuatnya dalam bentuk matriks. Lakukan perintah berikut ini :"
      ],
      "metadata": {
        "id": "aVd93P3BzKsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
        "    idf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        idf_table = {}\n",
        "\n",
        "        for word in f_table.keys():\n",
        "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
        "\n",
        "        idf_matrix[sent] = idf_table\n",
        "\n",
        "    return idf_matrix\n",
        "\n",
        "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
        "print(idf_matrix)\n"
      ],
      "metadata": {
        "id": "0nRmt_LszEuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a857cd4c-5f61-4286-8c87-0289224b9eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\\nuntuk mencapai herd immunity di Indonesia sangat besar.': {'kebutuhan': 0.6020599913279624, 'vaksin': 0.3010299956639812, 'program': 0.6020599913279624, 'vaksinasi': 0.6020599913279624, 'penanganan': 0.6020599913279624, 'pandemi': 0.6020599913279624, 'covid-19': 0.6020599913279624, 'mencapai': 0.6020599913279624, 'herd': 0.6020599913279624, 'immun': 0.6020599913279624, 'indonesia': 0.6020599913279624, '.': 0.3010299956639812}, 'Untuk itu, Pemerintah mengupayakan\\nketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.': {',': 0.6020599913279624, 'pemerintah': 0.6020599913279624, 'mengupayakan': 0.6020599913279624, 'ketersediaan': 0.6020599913279624, 'vaksin': 0.3010299956639812, 'sumber': 0.6020599913279624, 'salah': 0.6020599913279624, 'satunya': 0.6020599913279624, 'kerja': 0.6020599913279624, 'negara': 0.6020599913279624, '.': 0.3010299956639812}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\tMenghitung TF-IDF dan membuatnya dalam bentuk matriks. Lakukan perintah berikut ini :"
      ],
      "metadata": {
        "id": "3xAevNzBze-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
        "    tf_idf_matrix = {}\n",
        "\n",
        "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
        "        tf_idf_table = {}\n",
        "\n",
        "        for (word1, value1), (word2, value2) in zip(f_table1.items(), f_table2.items()):\n",
        "            tf_idf_table[word1] = float(value1 * value2)\n",
        "\n",
        "        tf_idf_matrix[sent1] = tf_idf_table\n",
        "\n",
        "    return tf_idf_matrix\n",
        "\n",
        "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
        "print(tf_idf_matrix)\n"
      ],
      "metadata": {
        "id": "tWSM_JqDziOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0315cb-e512-4dc5-fb7c-c758a922070d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\\nuntuk mencapai herd immunity di Indonesia sangat besar.': {'kebutuhan': 0.050171665943996864, 'vaksin': 0.025085832971998432, 'program': 0.050171665943996864, 'vaksinasi': 0.050171665943996864, 'penanganan': 0.050171665943996864, 'pandemi': 0.050171665943996864, 'covid-19': 0.050171665943996864, 'mencapai': 0.050171665943996864, 'herd': 0.050171665943996864, 'immun': 0.050171665943996864, 'indonesia': 0.050171665943996864, '.': 0.025085832971998432}, 'Untuk itu, Pemerintah mengupayakan\\nketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.': {',': 0.10946545296872044, 'pemerintah': 0.05473272648436022, 'mengupayakan': 0.05473272648436022, 'ketersediaan': 0.05473272648436022, 'vaksin': 0.02736636324218011, 'sumber': 0.05473272648436022, 'salah': 0.05473272648436022, 'satunya': 0.05473272648436022, 'kerja': 0.05473272648436022, 'negara': 0.05473272648436022, '.': 0.02736636324218011}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.\tMelakukan penskoran dari sebuah kalimat untuk memberi bobot pada paragraf. Lakukan perintah dibawah ini :"
      ],
      "metadata": {
        "id": "g-ajDYwtzlvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _score_sentences(tf_idf_matrix) -> dict:\n",
        "    sentenceValue = {}\n",
        "\n",
        "    for sent, f_table in tf_idf_matrix.items():\n",
        "        total_score_per_sentence = 0\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, score in f_table.items():\n",
        "            total_score_per_sentence += score\n",
        "\n",
        "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentenceValue\n",
        "\n",
        "sentence_scores = _score_sentences(tf_idf_matrix)\n",
        "print(sentence_scores)\n"
      ],
      "metadata": {
        "id": "uMaP4dnmzocy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33552b57-1424-43df-bb1a-b2b7e945eda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jumlah kebutuhan vaksin untuk program vaksinasi dalam penanganan pandemi COVID-19\\nuntuk mencapai herd immunity di Indonesia sangat besar.': 0.045990693781997126, 'Untuk itu, Pemerintah mengupayakan\\nketersediaan vaksin dari berbagai sumber, salah satunya melalui kerja sama dengan negara lain.': 0.05473272648436022}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average\n",
        " 8.\tProses selanjutnya adalah menghitung skor rata-rata dari kalimat. Lakukan perintah dibawah ini :"
      ],
      "metadata": {
        "id": "pY_dpM800wyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _find_average_score(sentenceValue) -> int:\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    average = sumValues / len(sentenceValue)\n",
        "    return average\n",
        "\n",
        "threshold = _find_average_score(sentence_scores)\n",
        "print(threshold)\n"
      ],
      "metadata": {
        "id": "nkcDTgEP1Pe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c95e9f0-ccf0-47d4-c25d-ac272d3cf3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05036171013317867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Langkah terakhir adalah melakukan ringkasan dengan memilih kalimat yang memiliki skor yang lebih dari skor rata-rata. Dalam kasus ini, digunakan nilai 1.3 untuk threshold. Lakukan perintah ini untuk melakukannya"
      ],
      "metadata": {
        "id": "Dhs8WDS41lvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary\n",
        "\n",
        "summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "Em3uxUJw1R2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a9572f-a996-4f08-efed-953798b86eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lakukan Langkah-langkah berikut ini :\n",
        "\n",
        "a.     Bentuklah sebuah variabel dengan nama contoh_raw yang berisi :“ Python is an interpreted high-level general-purpose programming language. Its design philosophy emphasizes code readability with its use of significant indentation. 40 Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects“.\n",
        "\n",
        "b.     Lalu lakukan proses untuk menghitung matrik frekuensi kata-kata dalam setiap kalimat dengan menggunakan stopwords “English”. Lakukan perhitungan skor rata-rata dari contoh_raw diatas!"
      ],
      "metadata": {
        "id": "Tl-__fTF2VzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat Variabel contoh_raw\n"
      ],
      "metadata": {
        "id": "fhupP8ce3HgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variabel contoh_raw berisi teks yang diberikan\n",
        "contoh_raw = \"\"\"Python is an interpreted high-level general-purpose programming language.\n",
        "Its design philosophy emphasizes code readability with its use of significant indentation.\n",
        "40 Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\"\"\"\n",
        "\n",
        "# Menampilkan isi dari contoh_raw\n",
        "print(contoh_raw)\n"
      ],
      "metadata": {
        "id": "7LdKC3Th2VKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd8c1e6-0721-4cb0-f626-76d01f43a142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is an interpreted high-level general-purpose programming language.\n",
            "Its design philosophy emphasizes code readability with its use of significant indentation.\n",
            "40 Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menghitung Matriks Frekuensi Kata & Skor Rata-rata"
      ],
      "metadata": {
        "id": "YGsZfhqr3WV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords jika belum tersedia\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenisasi kalimat\n",
        "sentences = sent_tokenize(contoh_raw)\n",
        "\n",
        "# Stopwords bahasa Inggris\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Membuat matriks frekuensi kata\n",
        "def create_freq_matrix(sentences):\n",
        "    freq_matrix = {}\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence.lower())  # Tokenisasi kata dan ubah ke lowercase\n",
        "        freq_table = {}\n",
        "\n",
        "        for word in words:\n",
        "            if word.isalnum() and word not in stop_words:  # Hanya ambil kata yang bukan stopwords\n",
        "                freq_table[word] = freq_table.get(word, 0) + 1\n",
        "\n",
        "        freq_matrix[sentence] = freq_table\n",
        "\n",
        "    return freq_matrix\n",
        "\n",
        "# Menghitung skor rata-rata\n",
        "def find_average_score(freq_matrix):\n",
        "    sentence_scores = {sentence: sum(freq_table.values()) / len(freq_table) if len(freq_table) > 0 else 0\n",
        "                       for sentence, freq_table in freq_matrix.items()}\n",
        "\n",
        "    average_score = sum(sentence_scores.values()) / len(sentence_scores) if len(sentence_scores) > 0 else 0\n",
        "    return sentence_scores, average_score\n",
        "\n",
        "# Menjalankan proses\n",
        "freq_matrix = create_freq_matrix(sentences)\n",
        "sentence_scores, average_score = find_average_score(freq_matrix)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Matriks Frekuensi Kata:\\n\", freq_matrix)\n",
        "print(\"\\nSkor Rata-rata:\\n\", average_score)\n"
      ],
      "metadata": {
        "id": "V6NMEvs-e_iC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca0b721-9451-4fa9-8abd-95b3fa05a57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriks Frekuensi Kata:\n",
            " {'Python is an interpreted high-level general-purpose programming language.': {'python': 1, 'interpreted': 1, 'programming': 1, 'language': 1}, 'Its design philosophy emphasizes code readability with its use of significant indentation.': {'design': 1, 'philosophy': 1, 'emphasizes': 1, 'code': 1, 'readability': 1, 'use': 1, 'significant': 1, 'indentation': 1}, '40 Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.': {'40': 1, 'language': 1, 'constructs': 1, 'well': 1, 'approach': 1, 'aim': 1, 'help': 1, 'programmers': 1, 'write': 1, 'clear': 1, 'logical': 1, 'code': 1, 'small': 1, 'projects': 1}}\n",
            "\n",
            "Skor Rata-rata:\n",
            " 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kesimpulan\n",
        "Dari hasil perhitungan matriks frekuensi kata, kita dapat melihat distribusi kata-kata yang memiliki makna penting dalam teks setelah menghilangkan stopwords. Skor rata-rata yang diperoleh mencerminkan seberapa signifikan kata-kata dalam setiap kalimat jika dibandingkan satu sama lain. Nilai ini bisa digunakan untuk menentukan bobot pentingnya suatu kalimat dalam konteks pemrosesan teks, seperti pembuatan ringkasan otomatis atau analisis teks lebih lanjut. Dengan pendekatan ini, kita dapat menyaring informasi lebih relevan secara efisien."
      ],
      "metadata": {
        "id": "qMjdaOF53l3C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SD48jjRypdho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}