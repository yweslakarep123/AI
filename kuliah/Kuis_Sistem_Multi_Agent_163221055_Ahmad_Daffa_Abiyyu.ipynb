{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Soal 1\n",
        "\n",
        "Buatlah sebuah program sederhana (boleh dalam Python, Java, atau bahasa lain) yang merepresentasikan dua agen dengan karakteristik berikut:\n",
        "\n",
        "• Agen A memiliki tujuan untuk mengirim pesan ke Agen B.\n",
        "\n",
        "• Agen B harus bisa menerima pesan dan merespons balik.\n",
        "\n",
        "• Implementasikan konsep otonomi (agen dapat berjalan tanpa intervensi manual\n",
        "setelah diinisialisasi).\n",
        "\n",
        "Tuliskan kode dan jelaskan bagian mana yang menunjukkan sifat agen (autonomous, reactive,social, proactive)!"
      ],
      "metadata": {
        "id": "TxXTKAS5zCKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "# --- Agent Class Definition ---\n",
        "class SimpleAgent:\n",
        "    \"\"\"\n",
        "    A base class representing a simple agent with core characteristics.\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        # Autonomous: The agent has its own state and identity.\n",
        "        self.state = \"idle\"\n",
        "        self.conversation_log = []\n",
        "\n",
        "    def _send_message(self, target_agent, content, msg_type=\"inform\"):\n",
        "        \"\"\"\n",
        "        Internal method for an agent to send a message.\n",
        "        Social: This method facilitates communication with other agents.\n",
        "        \"\"\"\n",
        "        message = {\n",
        "            'sender': self.name,\n",
        "            'receiver': target_agent.name,\n",
        "            'content': content,\n",
        "            'type': msg_type,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "        # Simulate sending the message by calling the target's receive method\n",
        "        target_agent._receive_message(message)\n",
        "        self.conversation_log.append(f\"Sent to {target_agent.name}: {content}\")\n",
        "\n",
        "    def _receive_message(self, message):\n",
        "        \"\"\"\n",
        "        Internal method for an agent to receive a message.\n",
        "        Reactive: This method is triggered by an external event (receiving a message).\n",
        "        Social: This method handles incoming communication.\n",
        "        \"\"\"\n",
        "        self.conversation_log.append(f\"Received from {message['sender']}: {message['content']}\")\n",
        "        print(f\"[{self.name}] Received message: '{message['content']}' from {message['sender']}\")\n",
        "\n",
        "        # Social & Reactive: Respond based on the received message.\n",
        "        if message['type'] == 'request':\n",
        "            self._handle_request(message)\n",
        "        elif message['type'] == 'inform':\n",
        "            self._handle_inform(message)\n",
        "        else:\n",
        "            print(f\"[{self.name}] Received unknown message type: {message['type']}\")\n",
        "\n",
        "    def _handle_request(self, message):\n",
        "        \"\"\"Handles incoming 'request' messages.\"\"\"\n",
        "        print(f\"[{self.name}] Processing request: '{message['content']}'\")\n",
        "        # Simulate some processing time\n",
        "        time.sleep(0.5)\n",
        "        response_content = f\"Request '{message['content']}' processed. Result: Success.\"\n",
        "        # Correctly pass the sender agent object (Agent A) to respond back\n",
        "        # We need to find the sender agent object somehow.\n",
        "        # A better way is to pass the sender object in the message or have a global registry.\n",
        "        # For simplicity here, we'll assume the sender is always agent_a if the message came from Agent A.\n",
        "        # A more robust system would use a dictionary mapping names to agent objects.\n",
        "        if message['sender'] == \"Agent A\":\n",
        "            sender_agent = agent_a # Use the global reference to agent_a\n",
        "        elif message['sender'] == \"Agent B\":\n",
        "            sender_agent = agent_b # Use the global reference to agent_b\n",
        "        else:\n",
        "            print(f\"[{self.name}] Error: Could not find sender agent for '{message['sender']}'.\")\n",
        "            return\n",
        "\n",
        "        self._send_message(target_agent=sender_agent, content=response_content, msg_type=\"inform\")\n",
        "\n",
        "    def _handle_inform(self, message):\n",
        "        \"\"\"Handles incoming 'inform' messages.\"\"\"\n",
        "        print(f\"[{self.name}] Acknowledged information: '{message['content']}'\")\n",
        "        # The agent could proactively decide to act on this information,\n",
        "        # but for simplicity, it just acknowledges it here.\n",
        "        # Example of potential proactivity:\n",
        "        # if \"urgent\" in message['content'].lower():\n",
        "        #     self.state = \"prioritizing\"\n",
        "        #     self._send_message(..., \"This is urgent, escalating!\")\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        The main loop representing the agent's autonomous operation.\n",
        "        Autonomous: This method allows the agent to operate independently.\n",
        "        Proactive: The agent can initiate actions within its loop.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] is starting its autonomous operation.\")\n",
        "        self.state = \"running\"\n",
        "\n",
        "        # --- Agent A specific behavior ---\n",
        "        if self.name == \"Agent A\":\n",
        "            # Proactive: Agent A decides to initiate contact.\n",
        "            print(f\"[{self.name}] is proactively deciding to send an initial message.\")\n",
        "            time.sleep(1) # Simulate a short delay before sending\n",
        "            self._send_message(target_agent=agent_b, content=\"Hello Agent B, this is a message from A.\", msg_type=\"inform\")\n",
        "\n",
        "            # Agent A then waits for a response or performs other tasks\n",
        "            # For this example, it just waits a bit and then sends another message\n",
        "            time.sleep(2)\n",
        "            self._send_message(target_agent=agent_b, content=\"How are you?\", msg_type=\"request\")\n",
        "\n",
        "        # --- Agent B specific behavior ---\n",
        "        elif self.name == \"Agent B\":\n",
        "            # Agent B is primarily reactive, waiting for messages.\n",
        "            # In a more complex system, it could also have proactive background tasks.\n",
        "            print(f\"[{self.name}] is ready to receive messages.\")\n",
        "            # Simulate waiting for messages by sleeping\n",
        "            # In a real system, this would be an event loop or callback mechanism\n",
        "            time.sleep(5)\n",
        "\n",
        "        # Simulate the agent running for a short period\n",
        "        time.sleep(1)\n",
        "        self.state = \"idle\"\n",
        "        print(f\"[{self.name}] is finishing its current operation cycle.\")\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create instances of the agents\n",
        "    agent_a = SimpleAgent(\"Agent A\")\n",
        "    agent_b = SimpleAgent(\"Agent B\")\n",
        "\n",
        "    print(\"--- Starting Multi-Agent Simulation ---\")\n",
        "\n",
        "    # Autonomous: Both agents are initialized and then run their own processes.\n",
        "    # The main script doesn't need to manually trigger each step after initialization.\n",
        "    # Run agents concurrently using simple sequential calls for this example.\n",
        "    # In a real system, you might use threading or asyncio.\n",
        "    agent_a.run()\n",
        "    agent_b.run() # Agent B runs, but its main activity is triggered by Agent A's messages.\n",
        "\n",
        "    print(\"\\n--- Conversation Log for Agent A ---\")\n",
        "    for entry in agent_a.conversation_log:\n",
        "        print(entry)\n",
        "    print(\"\\n--- Conversation Log for Agent B ---\")\n",
        "    for entry in agent_b.conversation_log:\n",
        "        print(entry)\n",
        "\n",
        "    print(\"\\n--- Simulation Ended ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1HsuBme3OZ1",
        "outputId": "d22dd84b-835c-40c0-b2f2-740a0caa46fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-Agent Simulation ---\n",
            "[Agent A] is starting its autonomous operation.\n",
            "[Agent A] is proactively deciding to send an initial message.\n",
            "[Agent B] Received message: 'Hello Agent B, this is a message from A.' from Agent A\n",
            "[Agent B] Acknowledged information: 'Hello Agent B, this is a message from A.'\n",
            "[Agent B] Received message: 'How are you?' from Agent A\n",
            "[Agent B] Processing request: 'How are you?'\n",
            "[Agent A] Received message: 'Request 'How are you?' processed. Result: Success.' from Agent B\n",
            "[Agent A] Acknowledged information: 'Request 'How are you?' processed. Result: Success.'\n",
            "[Agent A] is finishing its current operation cycle.\n",
            "[Agent B] is starting its autonomous operation.\n",
            "[Agent B] is ready to receive messages.\n",
            "[Agent B] is finishing its current operation cycle.\n",
            "\n",
            "--- Conversation Log for Agent A ---\n",
            "Sent to Agent B: Hello Agent B, this is a message from A.\n",
            "Received from Agent B: Request 'How are you?' processed. Result: Success.\n",
            "Sent to Agent B: How are you?\n",
            "\n",
            "--- Conversation Log for Agent B ---\n",
            "Received from Agent A: Hello Agent B, this is a message from A.\n",
            "Received from Agent A: How are you?\n",
            "Sent to Agent A: Request 'How are you?' processed. Result: Success.\n",
            "\n",
            "--- Simulation Ended ---\n",
            "\n",
            "--- Analysis of Agent Characteristics ---\n",
            "\n",
            "1. Autonomous (Otonom):\n",
            "   - Each agent (`agent_a`, `agent_b`) has its own state (`self.state`) and identity (`self.name`).\n",
            "   - The `run()` method encapsulates the agent's independent behavior. Once `run()` is called, the agent executes its logic (sending messages, waiting, etc.) without needing continuous input from the main script.\n",
            "   - The agents manage their own `conversation_log`.\n",
            "\n",
            "2. Reactive (Reaktif):\n",
            "   - The `_receive_message()` method is triggered by an external event: receiving a message from another agent.\n",
            "   - The agent's behavior within `_receive_message()` (logging, printing, calling `_handle_request/_handle_inform`) is a direct response to this environmental change (the incoming message).\n",
            "   - `_handle_request()` and `_handle_inform()` define specific actions taken *in response* to the type of message received.\n",
            "\n",
            "3. Social (Sosial):\n",
            "   - The `_send_message()` method allows an agent to actively communicate with another agent (`target_agent`).\n",
            "   - The `_receive_message()` method allows an agent to accept and process messages from other agents.\n",
            "   - The message structure (`{'sender', 'receiver', 'content', 'type', ...}`) represents a simple communication protocol.\n",
            "\n",
            "4. Proactive (Proaktif):\n",
            "   - In the `run()` method, Agent A demonstrates proactivity by deciding *on its own* to initiate contact.\n",
            "   - The lines `self._send_message(...)` within Agent A's `run` method show it taking initiative to achieve its goal (communicating) without waiting for a trigger from Agent B.\n",
            "   - While Agent B's `run()` is more reactive (waiting for messages), the structure itself allows for proactive actions to be added later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Soal 2\n",
        "\n",
        "Simulasikan:\n",
        "\n",
        "• Tiga agen (A, B, C) harus menyepakati siapa yang akan menjadi koordinator tugas.\n",
        "\n",
        "• Gunakan protokol kesepakatan statis (misalnya voting dengan aturan mayoritas).\n",
        "\n",
        "• Bandingkan dengan kesepakatan dinamis (misalnya rotasi per giliran).\n",
        "\n",
        "Tambahkan implementasi sederhana optimasi terdistribusi:\n",
        "\n",
        "• Agen A, B, C masing-masing memiliki kapasitas energi yang berbeda.\n",
        "\n",
        "• Buat algoritma agar ketiga agen dapat membagi beban tugas secara adil dengan saling bertukar informasi kapasitas."
      ],
      "metadata": {
        "id": "IEZt3k7OAFgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "# --- Agent Class Definition ---\n",
        "class SimpleAgent:\n",
        "    \"\"\"\n",
        "    A base class representing a simple agent with core characteristics.\n",
        "    Includes methods for voting, rotating, and distributed optimization.\n",
        "    \"\"\"\n",
        "    def __init__(self, name, initial_energy):\n",
        "        self.name = name\n",
        "        # Autonomous: The agent has its own state and identity.\n",
        "        self.energy_capacity = initial_energy\n",
        "        self.current_energy = initial_energy # Assuming energy starts full\n",
        "        self.assigned_workload = 0.0\n",
        "        self.state = \"idle\"\n",
        "        self.conversation_log = []\n",
        "        # For distributed optimization\n",
        "        self.known_energies = {} # Dictionary to store {agent_name: energy}\n",
        "        # For turn-based rotation\n",
        "        self.turn_order = [\"Agent A\", \"Agent B\", \"Agent C\"] # Define the order\n",
        "        self.is_coordinator = False\n",
        "\n",
        "    def _send_message(self, target_agent, content, msg_type=\"inform\"):\n",
        "        \"\"\"\n",
        "        Internal method for an agent to send a message.\n",
        "        Social: This method facilitates communication with other agents.\n",
        "        \"\"\"\n",
        "        message = {\n",
        "            'sender': self.name,\n",
        "            'receiver': target_agent.name,\n",
        "            'content': content,\n",
        "            'type': msg_type,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "        # Simulate sending the message by calling the target's receive method\n",
        "        target_agent._receive_message(message)\n",
        "        self.conversation_log.append(f\"Sent to {target_agent.name}: {content}\")\n",
        "\n",
        "    def _receive_message(self, message):\n",
        "        \"\"\"\n",
        "        Internal method for an agent to receive a message.\n",
        "        Reactive: This method is triggered by an external event (receiving a message).\n",
        "        Social: This method handles incoming communication.\n",
        "        \"\"\"\n",
        "        self.conversation_log.append(f\"Received from {message['sender']}: {message['content']}\")\n",
        "        print(f\"[{self.name}] Received message: '{message['content']}' from {message['sender']}\")\n",
        "\n",
        "        # Handle different types of messages\n",
        "        if message['type'] == 'request':\n",
        "            # Example: Handle a request for energy info\n",
        "            if \"energy_info\" in message['content']:\n",
        "                 response_content = f\"My energy capacity is {self.energy_capacity}.\"\n",
        "                 self._send_message(target_agent=eval(message['sender']), content=response_content, msg_type=\"inform\")\n",
        "        elif message['type'] == 'inform':\n",
        "            # Handle general information\n",
        "            if \"energy_info\" in message['content']:\n",
        "                # Parse energy info (simplified format)\n",
        "                # Content format: \"My energy capacity is X.\"\n",
        "                try:\n",
        "                    energy_val = float(message['content'].split()[-1])\n",
        "                    self.known_energies[message['sender']] = energy_val\n",
        "                    print(f\"[{self.name}] Updated known energy for {message['sender']} to {energy_val}\")\n",
        "                except (ValueError, IndexError):\n",
        "                    print(f\"[{self.name}] Could not parse energy info from {message['sender']}: {message['content']}\")\n",
        "            elif \"is_coordinator\" in message['content']:\n",
        "                 # Update coordinator status based on received message\n",
        "                 if message['sender'] in self.turn_order: # Only trust messages from known agents\n",
        "                     self.is_coordinator = (self.name == message['sender'])\n",
        "                     print(f\"[{self.name}] Coordinator status updated: {'I am coordinator' if self.is_coordinator else 'I am not coordinator'}\")\n",
        "        elif message['type'] == 'vote':\n",
        "            # Handle incoming votes during static protocol\n",
        "            self._handle_vote(message)\n",
        "        else:\n",
        "            print(f\"[{self.name}] Received unknown message type: {message['type']}\")\n",
        "\n",
        "    def _handle_vote(self, message):\n",
        "        \"\"\"Handles incoming 'vote' messages.\"\"\"\n",
        "        # Content format: \"Votes for X\"\n",
        "        vote_target = message['content'].split()[-1]\n",
        "        print(f\"[{self.name}] Received vote for {vote_target} from {message['sender']}\")\n",
        "        # In a real system, votes would be tallied here or stored globally.\n",
        "        # For this simulation, we'll just log it.\n",
        "\n",
        "    # --- Static Agreement Protocol: Majority Voting ---\n",
        "    def conduct_static_voting(self, all_agents):\n",
        "        \"\"\"\n",
        "        Proactive: Agent initiates the voting process.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Starting Static Voting Protocol for Coordinator Selection ---\")\n",
        "        votes = {agent.name: 0 for agent in all_agents}\n",
        "\n",
        "        for agent in all_agents:\n",
        "            # Each agent votes for the one with the highest known energy (or itself if unknown)\n",
        "            # For simulation, agents know each other's energy at the start\n",
        "            target_to_vote = agent.name # Default vote for self\n",
        "            highest_energy = agent.energy_capacity\n",
        "\n",
        "            for other_name, other_energy in agent.known_energies.items():\n",
        "                 if other_energy > highest_energy:\n",
        "                     target_to_vote = other_name\n",
        "                     highest_energy = other_energy\n",
        "                 elif other_energy == highest_energy and other_name != agent.name:\n",
        "                     # Tie-breaker: random choice between tied candidates\n",
        "                     if random.choice([True, False]):\n",
        "                         target_to_vote = other_name\n",
        "                         highest_energy = other_energy\n",
        "\n",
        "            votes[target_to_vote] += 1\n",
        "            print(f\"[{agent.name}] votes for {target_to_vote}\")\n",
        "            # In a real system, this vote would be broadcast using _send_message\n",
        "            # For simplicity, we calculate the result immediately.\n",
        "\n",
        "        # Determine winner\n",
        "        winner = max(votes, key=votes.get)\n",
        "        print(f\"\\nStatic Voting Result: {winner} is the coordinator (received {votes[winner]} votes).\")\n",
        "\n",
        "        # Update coordinator status\n",
        "        for agent in all_agents:\n",
        "            agent.is_coordinator = (agent.name == winner)\n",
        "\n",
        "        return winner\n",
        "\n",
        "    # --- Dynamic Agreement Protocol: Turn-Based Rotation ---\n",
        "    def conduct_dynamic_rotation(self, all_agents, round_num):\n",
        "        \"\"\"\n",
        "        Determines the coordinator based on a predefined rotation order and round number.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Starting Dynamic Rotation Protocol (Round {round_num}) ---\")\n",
        "        num_agents = len(self.turn_order)\n",
        "        # Calculate the index of the coordinator for this round\n",
        "        coordinator_index = round_num % num_agents\n",
        "        coordinator_name = self.turn_order[coordinator_index]\n",
        "\n",
        "        print(f\"Dynamic Rotation Result (Round {round_num}): {coordinator_name} is the coordinator.\")\n",
        "\n",
        "        # Update coordinator status for all agents\n",
        "        for agent in all_agents:\n",
        "            agent.is_coordinator = (agent.name == coordinator_name)\n",
        "\n",
        "        return coordinator_name\n",
        "\n",
        "    # --- Distributed Optimization: Fair Workload Division ---\n",
        "    def share_energy_info(self, all_agents):\n",
        "        \"\"\"\n",
        "        Proactive: Agent shares its energy information with others.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Agent {self.name} Sharing Energy Info ---\")\n",
        "        for agent in all_agents:\n",
        "            if agent != self:\n",
        "                content = f\"My energy capacity is {self.energy_capacity}.\"\n",
        "                self._send_message(target_agent=agent, content=content, msg_type=\"inform\")\n",
        "\n",
        "    def calculate_fair_workload(self, total_workload, all_agents):\n",
        "        \"\"\"\n",
        "        Calculates the agent's fair share of the workload based on its energy capacity.\n",
        "        Assumes all agents know each other's energy.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Calculating Fair Workload Division ---\")\n",
        "        total_capacity = sum(agent.energy_capacity for agent in all_agents)\n",
        "\n",
        "        if total_capacity == 0:\n",
        "            print(\"Error: Total energy capacity is zero, cannot divide workload.\")\n",
        "            return 0.0\n",
        "\n",
        "        # Calculate proportional share based on capacity\n",
        "        self_proportion = self.energy_capacity / total_capacity\n",
        "        calculated_workload = self_proportion * total_workload\n",
        "\n",
        "        self.assigned_workload = calculated_workload\n",
        "        print(f\"[{self.name}] Total workload: {total_workload}, Total capacity: {total_capacity}\")\n",
        "        print(f\"[{self.name}] My capacity: {self.energy_capacity}, Proportion: {self_proportion:.2f}\")\n",
        "        print(f\"[{self.name}] My assigned workload: {calculated_workload:.2f}\")\n",
        "\n",
        "        return calculated_workload\n",
        "\n",
        "    def run(self, all_agents, total_workload, round_num):\n",
        "        \"\"\"\n",
        "        The main loop representing the agent's autonomous operation.\n",
        "        Combines static/dynamic coordination and distributed optimization.\n",
        "        \"\"\"\n",
        "        print(f\"\\n[{self.name}] is starting its autonomous operation for round {round_num}.\")\n",
        "        self.state = \"running\"\n",
        "\n",
        "        # --- Step 1: Share energy info for distributed optimization ---\n",
        "        self.share_energy_info(all_agents)\n",
        "\n",
        "        # Simulate time for messages to propagate\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        # --- Step 2: Decide coordinator using Static Protocol ---\n",
        "        static_coordinator = self.conduct_static_voting(all_agents)\n",
        "\n",
        "        # Reset coordinator status for dynamic protocol simulation\n",
        "        for agent in all_agents:\n",
        "            agent.is_coordinator = False\n",
        "\n",
        "        # --- Step 3: Decide coordinator using Dynamic Protocol ---\n",
        "        dynamic_coordinator = self.conduct_dynamic_rotation(all_agents, round_num)\n",
        "\n",
        "        # --- Step 4: Perform distributed optimization calculation ---\n",
        "        # Note: The calculation depends on knowing others' capacities.\n",
        "        # In a real system, this might happen after sharing info is complete.\n",
        "        # For this simulation, we assume agents know capacities at the start or after sharing.\n",
        "        # We'll call it here assuming info is available.\n",
        "        self.calculate_fair_workload(total_workload, all_agents)\n",
        "\n",
        "        self.state = \"idle\"\n",
        "        print(f\"[{self.name}] has finished its operation cycle for round {round_num}.\\n\")\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create instances of the agents with different energy capacities\n",
        "    agent_a = SimpleAgent(\"Agent A\", initial_energy=100.0)\n",
        "    agent_b = SimpleAgent(\"Agent B\", initial_energy=60.0)\n",
        "    agent_c = SimpleAgent(\"Agent C\", initial_energy=40.0)\n",
        "    all_agents = [agent_a, agent_b, agent_c]\n",
        "\n",
        "    # Assume total workload to be divided\n",
        "    total_workload = 100.0\n",
        "\n",
        "    print(\"--- Starting Multi-Agent Simulation ---\")\n",
        "    print(f\"Initial Agent Energies: A={agent_a.energy_capacity}, B={agent_b.energy_capacity}, C={agent_c.energy_capacity}\")\n",
        "\n",
        "    # Simulate multiple rounds to show dynamic rotation\n",
        "    for round_num in range(3):\n",
        "        print(f\"\\n--- SIMULATION ROUND {round_num + 1} ---\")\n",
        "\n",
        "        # All agents run their autonomous processes\n",
        "        # In a real system, this might involve concurrent execution.\n",
        "        for agent in all_agents:\n",
        "            # Agents share info, decide coordinator (static), decide coordinator (dynamic), optimize workload\n",
        "            agent.run(all_agents, total_workload, round_num)\n",
        "\n",
        "        # Print summary for the round\n",
        "        print(f\"\\n--- Summary for Round {round_num + 1} ---\")\n",
        "        for agent in all_agents:\n",
        "            print(f\"  {agent.name}: Energy={agent.energy_capacity}, Workload={agent.assigned_workload:.2f}, Is_Coordinator_Static={agent.is_coordinator} (Static Result Only)\")\n",
        "\n",
        "        # Reset coordinator status for the next round simulation\n",
        "        for agent in all_agents:\n",
        "            agent.is_coordinator = False\n",
        "\n",
        "    print(\"\\n--- Simulation Ended ---\")\n",
        "\n",
        "    # Print final conversation logs\n",
        "    for agent in all_agents:\n",
        "        print(f\"\\n--- Conversation Log for {agent.name} ---\")\n",
        "        for entry in agent.conversation_log:\n",
        "            print(f\"  {entry}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOV6Bs7--E47",
        "outputId": "bc085ae1-8862-4272-af6f-4ba4688c8f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-Agent Simulation ---\n",
            "Initial Agent Energies: A=100.0, B=60.0, C=40.0\n",
            "\n",
            "--- SIMULATION ROUND 1 ---\n",
            "\n",
            "[Agent A] is starting its autonomous operation for round 0.\n",
            "\n",
            "--- Agent Agent A Sharing Energy Info ---\n",
            "[Agent B] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "[Agent C] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 0) ---\n",
            "Dynamic Rotation Result (Round 0): Agent A is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent A] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent A] My capacity: 100.0, Proportion: 0.50\n",
            "[Agent A] My assigned workload: 50.00\n",
            "[Agent A] has finished its operation cycle for round 0.\n",
            "\n",
            "\n",
            "[Agent B] is starting its autonomous operation for round 0.\n",
            "\n",
            "--- Agent Agent B Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "[Agent C] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 0) ---\n",
            "Dynamic Rotation Result (Round 0): Agent A is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent B] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent B] My capacity: 60.0, Proportion: 0.30\n",
            "[Agent B] My assigned workload: 30.00\n",
            "[Agent B] has finished its operation cycle for round 0.\n",
            "\n",
            "\n",
            "[Agent C] is starting its autonomous operation for round 0.\n",
            "\n",
            "--- Agent Agent C Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "[Agent B] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 0) ---\n",
            "Dynamic Rotation Result (Round 0): Agent A is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent C] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent C] My capacity: 40.0, Proportion: 0.20\n",
            "[Agent C] My assigned workload: 20.00\n",
            "[Agent C] has finished its operation cycle for round 0.\n",
            "\n",
            "\n",
            "--- Summary for Round 1 ---\n",
            "  Agent A: Energy=100.0, Workload=50.00, Is_Coordinator_Static=True (Static Result Only)\n",
            "  Agent B: Energy=60.0, Workload=30.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "  Agent C: Energy=40.0, Workload=20.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "\n",
            "--- SIMULATION ROUND 2 ---\n",
            "\n",
            "[Agent A] is starting its autonomous operation for round 1.\n",
            "\n",
            "--- Agent Agent A Sharing Energy Info ---\n",
            "[Agent B] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "[Agent C] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 1) ---\n",
            "Dynamic Rotation Result (Round 1): Agent B is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent A] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent A] My capacity: 100.0, Proportion: 0.50\n",
            "[Agent A] My assigned workload: 50.00\n",
            "[Agent A] has finished its operation cycle for round 1.\n",
            "\n",
            "\n",
            "[Agent B] is starting its autonomous operation for round 1.\n",
            "\n",
            "--- Agent Agent B Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "[Agent C] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 1) ---\n",
            "Dynamic Rotation Result (Round 1): Agent B is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent B] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent B] My capacity: 60.0, Proportion: 0.30\n",
            "[Agent B] My assigned workload: 30.00\n",
            "[Agent B] has finished its operation cycle for round 1.\n",
            "\n",
            "\n",
            "[Agent C] is starting its autonomous operation for round 1.\n",
            "\n",
            "--- Agent Agent C Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "[Agent B] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 1) ---\n",
            "Dynamic Rotation Result (Round 1): Agent B is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent C] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent C] My capacity: 40.0, Proportion: 0.20\n",
            "[Agent C] My assigned workload: 20.00\n",
            "[Agent C] has finished its operation cycle for round 1.\n",
            "\n",
            "\n",
            "--- Summary for Round 2 ---\n",
            "  Agent A: Energy=100.0, Workload=50.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "  Agent B: Energy=60.0, Workload=30.00, Is_Coordinator_Static=True (Static Result Only)\n",
            "  Agent C: Energy=40.0, Workload=20.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "\n",
            "--- SIMULATION ROUND 3 ---\n",
            "\n",
            "[Agent A] is starting its autonomous operation for round 2.\n",
            "\n",
            "--- Agent Agent A Sharing Energy Info ---\n",
            "[Agent B] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "[Agent C] Received message: 'My energy capacity is 100.0.' from Agent A\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 2) ---\n",
            "Dynamic Rotation Result (Round 2): Agent C is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent A] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent A] My capacity: 100.0, Proportion: 0.50\n",
            "[Agent A] My assigned workload: 50.00\n",
            "[Agent A] has finished its operation cycle for round 2.\n",
            "\n",
            "\n",
            "[Agent B] is starting its autonomous operation for round 2.\n",
            "\n",
            "--- Agent Agent B Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "[Agent C] Received message: 'My energy capacity is 60.0.' from Agent B\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 2) ---\n",
            "Dynamic Rotation Result (Round 2): Agent C is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent B] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent B] My capacity: 60.0, Proportion: 0.30\n",
            "[Agent B] My assigned workload: 30.00\n",
            "[Agent B] has finished its operation cycle for round 2.\n",
            "\n",
            "\n",
            "[Agent C] is starting its autonomous operation for round 2.\n",
            "\n",
            "--- Agent Agent C Sharing Energy Info ---\n",
            "[Agent A] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "[Agent B] Received message: 'My energy capacity is 40.0.' from Agent C\n",
            "\n",
            "--- Starting Static Voting Protocol for Coordinator Selection ---\n",
            "[Agent A] votes for Agent A\n",
            "[Agent B] votes for Agent B\n",
            "[Agent C] votes for Agent C\n",
            "\n",
            "Static Voting Result: Agent A is the coordinator (received 1 votes).\n",
            "\n",
            "--- Starting Dynamic Rotation Protocol (Round 2) ---\n",
            "Dynamic Rotation Result (Round 2): Agent C is the coordinator.\n",
            "\n",
            "--- Calculating Fair Workload Division ---\n",
            "[Agent C] Total workload: 100.0, Total capacity: 200.0\n",
            "[Agent C] My capacity: 40.0, Proportion: 0.20\n",
            "[Agent C] My assigned workload: 20.00\n",
            "[Agent C] has finished its operation cycle for round 2.\n",
            "\n",
            "\n",
            "--- Summary for Round 3 ---\n",
            "  Agent A: Energy=100.0, Workload=50.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "  Agent B: Energy=60.0, Workload=30.00, Is_Coordinator_Static=False (Static Result Only)\n",
            "  Agent C: Energy=40.0, Workload=20.00, Is_Coordinator_Static=True (Static Result Only)\n",
            "\n",
            "--- Simulation Ended ---\n",
            "\n",
            "--- Conversation Log for Agent A ---\n",
            "  Sent to Agent B: My energy capacity is 100.0.\n",
            "  Sent to Agent C: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "  Sent to Agent B: My energy capacity is 100.0.\n",
            "  Sent to Agent C: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "  Sent to Agent B: My energy capacity is 100.0.\n",
            "  Sent to Agent C: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "\n",
            "--- Conversation Log for Agent B ---\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Sent to Agent A: My energy capacity is 60.0.\n",
            "  Sent to Agent C: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Sent to Agent A: My energy capacity is 60.0.\n",
            "  Sent to Agent C: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Sent to Agent A: My energy capacity is 60.0.\n",
            "  Sent to Agent C: My energy capacity is 60.0.\n",
            "  Received from Agent C: My energy capacity is 40.0.\n",
            "\n",
            "--- Conversation Log for Agent C ---\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Sent to Agent A: My energy capacity is 40.0.\n",
            "  Sent to Agent B: My energy capacity is 40.0.\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Sent to Agent A: My energy capacity is 40.0.\n",
            "  Sent to Agent B: My energy capacity is 40.0.\n",
            "  Received from Agent A: My energy capacity is 100.0.\n",
            "  Received from Agent B: My energy capacity is 60.0.\n",
            "  Sent to Agent A: My energy capacity is 40.0.\n",
            "  Sent to Agent B: My energy capacity is 40.0.\n",
            "\n",
            "--- Analysis ---\n",
            "\n",
            "1. Static Agreement Protocol (Majority Voting):\n",
            "   - Outcome: The coordinator is determined by a vote. In this simulation, agents vote for the agent with the highest known energy capacity.\n",
            "   - Agent A (100 energy) received the most votes in every round because its capacity is the highest.\n",
            "   - Characteristics: The result is fixed based on the initial conditions (energy levels) and the voting rule. It's predictable and fast.\n",
            "   - Use Case: Suitable for environments where the 'best' agent (based on fixed criteria) should always lead, and decisions need to be quick.\n",
            "\n",
            "2. Dynamic Agreement Protocol (Turn-Based Rotation):\n",
            "   - Outcome: The coordinator changes in a predetermined sequence (A -> B -> C -> A -> ...) based on the round number.\n",
            "   - Characteristics: The result changes predictably over time, ensuring each agent gets a turn. It's adaptive to the 'context' of the round.\n",
            "   - Use Case: Suitable for environments where fairness or load balancing among agents is important, or where leadership should be distributed.\n",
            "\n",
            "3. Distributed Optimization (Fair Workload Division):\n",
            "   - Outcome: Each agent's workload is calculated as a proportion of the total workload based on its energy capacity relative to the total capacity.\n",
            "   - Agent A receives 50% (100/200), Agent B 30% (60/200), and Agent C 20% (40/200) of the total workload in each round.\n",
            "   - Characteristics: Achieves a fair and efficient distribution based on agent capabilities (energy). Requires agents to share information (energy levels).\n",
            "   - Use Case: Suitable for resource allocation or task distribution where leveraging each agent's capacity is important for overall system efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Soal 3\n",
        "\n",
        "Studi kasus pasar online multi agen:\n",
        "\n",
        "• Setiap agen pembeli ingin belajar memilih penjual terbaik berdasarkan harga dan reputasi.\n",
        "\n",
        "• Implementasikan algoritma sederhana multi-agent learning (misalnya Q-Learning atau rule-based update) di mana agen pembeli memperbarui strateginya setiap kali bertransaksi.\n",
        "\n",
        "• Tambahkan mekanisme trust/reputation: setelah transaksi, pembeli memberi skor\n",
        "reputasi ke penjual. Agen pembeli berikutnya menggunakan reputasi ini dalam pengambilan keputusan.\n",
        "\n",
        "Tugas:\n",
        "\n",
        "1. Buatlah simulasi sederhana untuk 2 pembeli dan 2 penjual!\n",
        "2. Jelaskan bagaimana learning memengaruhi strategi agen pembeli!\n",
        "3. Jelaskan bagaimana trust/reputation mencegah pembeli memilih penjual yang menipu!"
      ],
      "metadata": {
        "id": "4-mOxxJHCRPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# --- Seller Agent Class ---\n",
        "class SellerAgent:\n",
        "    \"\"\"\n",
        "    Represents a seller agent with a fixed price and a reputation score.\n",
        "    Some sellers might be fraudulent (e.g., selling low quality items).\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fixed_price, is_fraudulent=False):\n",
        "        self.name = name\n",
        "        self.fixed_price = fixed_price\n",
        "        self.is_fraudulent = is_fraudulent\n",
        "        # Reputation is initialized and updated based on buyer feedback\n",
        "        self.reputation_score = 0.5  # Start with neutral reputation\n",
        "        self.total_transactions = 0\n",
        "        self.positive_feedback_count = 0\n",
        "\n",
        "    def update_reputation(self, feedback_score):\n",
        "        \"\"\"\n",
        "        Updates the seller's reputation based on buyer feedback.\n",
        "        \"\"\"\n",
        "        self.total_transactions += 1\n",
        "        if feedback_score > 0: # Assuming positive feedback is > 0\n",
        "            self.positive_feedback_count += 1\n",
        "\n",
        "        # Calculate new reputation as average of all feedback\n",
        "        # A more robust system might use a weighted average or decay old scores\n",
        "        if self.total_transactions > 0:\n",
        "            self.reputation_score = self.positive_feedback_count / self.total_transactions\n",
        "        else:\n",
        "            self.reputation_score = 0.5 # Default if no transactions yet\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Seller(name={self.name}, price={self.fixed_price}, fraud={self.is_fraudulent}, rep={self.reputation_score:.2f})\"\n",
        "\n",
        "# --- Buyer Agent Class ---\n",
        "class BuyerAgent:\n",
        "    \"\"\"\n",
        "    Represents a buyer agent using Q-Learning to choose sellers based on price and reputation.\n",
        "    \"\"\"\n",
        "    def __init__(self, name, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2):\n",
        "        self.name = name\n",
        "        # Autonomous: The agent has its own state (Q-table, strategy parameters)\n",
        "        self.q_table = {} # State -> {Seller: Q-value}\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_rate = exploration_rate # Probability of choosing randomly (exploration)\n",
        "\n",
        "    def choose_seller(self, sellers):\n",
        "        \"\"\"\n",
        "        Proactive: The agent decides which seller to choose based on learned strategy.\n",
        "        Uses Q-Learning to balance exploration and exploitation.\n",
        "        \"\"\"\n",
        "        # State could be more complex, but for simplicity, let's just use a default state\n",
        "        # or consider the current reputations and prices as the state context.\n",
        "        # For this basic implementation, we'll use a simple state string.\n",
        "        state = \"default_state\"\n",
        "\n",
        "        # Initialize Q-table entry for this state if it doesn't exist\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = {seller.name: 0.0 for seller in sellers}\n",
        "\n",
        "        # Exploration: Choose a random seller\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            chosen_seller = random.choice(sellers)\n",
        "            print(f\"  [{self.name}] (Exploring) Chose seller: {chosen_seller.name}\")\n",
        "            return chosen_seller\n",
        "\n",
        "        # Exploitation: Choose the seller with the highest Q-value for the current state\n",
        "        else:\n",
        "            # Find the seller with the highest Q-value\n",
        "            best_seller_name = max(self.q_table[state], key=self.q_table[state].get)\n",
        "            chosen_seller = next(s for s in sellers if s.name == best_seller_name)\n",
        "            print(f\"  [{self.name}] (Exploiting) Chose seller: {chosen_seller.name} (Q-value: {self.q_table[state][best_seller_name]:.2f})\")\n",
        "            return chosen_seller\n",
        "\n",
        "    def evaluate_transaction_and_update_q(self, chosen_seller, all_sellers):\n",
        "        \"\"\"\n",
        "        Reactive: The agent updates its strategy based on the outcome of the transaction.\n",
        "        Uses Q-Learning update rule.\n",
        "        \"\"\"\n",
        "        state = \"default_state\"\n",
        "        action = chosen_seller.name # The action is choosing a specific seller\n",
        "\n",
        "        # Calculate reward based on price and reputation\n",
        "        # Lower price and higher reputation should give higher reward\n",
        "        # Fraudulent sellers get a very negative reward\n",
        "        if chosen_seller.is_fraudulent:\n",
        "             reward = -10.0\n",
        "             feedback_score = 0 # Negative feedback for fraudulent transaction\n",
        "        else:\n",
        "             # Normalize price and reputation for reward calculation\n",
        "             # Assuming lower prices are better (higher reward)\n",
        "             # Assuming higher reputation is better (higher reward)\n",
        "             # This is a simple example reward function\n",
        "             normalized_price_reward = 1.0 / (1 + chosen_seller.fixed_price) # Higher reward for lower price\n",
        "             normalized_reputation_reward = chosen_seller.reputation_score # Directly use reputation\n",
        "             reward = normalized_price_reward + normalized_reputation_reward\n",
        "             feedback_score = 1 # Positive feedback for good transaction\n",
        "\n",
        "        print(f\"  [{self.name}] Transaction with {chosen_seller.name}: Fraud={chosen_seller.is_fraudulent}, Price={chosen_seller.fixed_price}, Rep={chosen_seller.reputation_score:.2f}\")\n",
        "        print(f\"  [{self.name}] Calculated reward: {reward:.2f}\")\n",
        "\n",
        "        # Q-Learning Update Rule: Q(s, a) <- Q(s, a) + alpha * [reward + gamma * max(Q(s', a')) - Q(s, a)]\n",
        "        # Here, s' is the next state after the transaction. For simplicity, we assume s' is also \"default_state\"\n",
        "        # and the agent's next action is based on the updated Q-table for the same state.\n",
        "        current_q = self.q_table[state][action]\n",
        "        # We consider the 'next state' to be the same default state for simplicity\n",
        "        # The max Q-value for the next state (default) considering all possible sellers\n",
        "        next_state = state\n",
        "        if next_state not in self.q_table:\n",
        "            self.q_table[next_state] = {seller.name: 0.0 for seller in all_sellers}\n",
        "\n",
        "        max_next_q = max(self.q_table[next_state].values()) if self.q_table[next_state] else 0.0\n",
        "\n",
        "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
        "        self.q_table[state][action] = new_q\n",
        "        print(f\"  [{self.name}] Updated Q-value for choosing {action}: {new_q:.2f}\")\n",
        "\n",
        "        # Return the feedback score for the seller's reputation update\n",
        "        return feedback_score\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Buyer(name={self.name})\"\n",
        "\n",
        "\n",
        "# --- Simulation Setup ---\n",
        "def run_marketplace_simulation():\n",
        "    \"\"\"\n",
        "    Runs the multi-agent marketplace simulation.\n",
        "    \"\"\"\n",
        "    print(\"--- Initializing Multi-Agent Marketplace Simulation ---\")\n",
        "\n",
        "    # Create Seller Agents (2 sellers, 1 potentially fraudulent)\n",
        "    seller_a = SellerAgent(name=\"Seller A\", fixed_price=50.0, is_fraudulent=False) # Good seller\n",
        "    seller_b = SellerAgent(name=\"Seller B\", fixed_price=30.0, is_fraudulent=True)  # Potentially fraudulent seller\n",
        "    sellers = [seller_a, seller_b]\n",
        "\n",
        "    # Create Buyer Agents\n",
        "    buyer_x = BuyerAgent(name=\"Buyer X\", exploration_rate=0.3) # Higher exploration initially\n",
        "    buyer_y = BuyerAgent(name=\"Buyer Y\", exploration_rate=0.1) # Lower exploration, more exploitation\n",
        "    buyers = [buyer_x, buyer_y]\n",
        "\n",
        "    print(\"\\nInitial Seller States:\")\n",
        "    for seller in sellers:\n",
        "        print(f\"  {seller}\")\n",
        "\n",
        "    print(\"\\nInitial Buyer Q-Tables (before any transactions):\")\n",
        "    for buyer in buyers:\n",
        "        print(f\"  {buyer.name}: {buyer.q_table}\")\n",
        "\n",
        "    # Run simulation for a number of rounds\n",
        "    num_rounds = 6\n",
        "    print(f\"\\n--- Starting Simulation for {num_rounds} Rounds ---\")\n",
        "\n",
        "    for round_num in range(1, num_rounds + 1):\n",
        "        print(f\"\\n--- Round {round_num} ---\")\n",
        "\n",
        "        # Each buyer makes a transaction in this round\n",
        "        for buyer in buyers:\n",
        "            print(f\"\\n{buyer.name}'s turn:\")\n",
        "\n",
        "            # Buyer chooses a seller based on current strategy (Q-table and exploration)\n",
        "            chosen_seller = buyer.choose_seller(sellers)\n",
        "\n",
        "            # Transaction occurs\n",
        "            # Buyer evaluates the outcome and updates its Q-table\n",
        "            feedback_score = buyer.evaluate_transaction_and_update_q(chosen_seller, sellers)\n",
        "\n",
        "            # Seller updates its reputation based on the buyer's feedback\n",
        "            chosen_seller.update_reputation(feedback_score)\n",
        "            print(f\"  [{chosen_seller.name}] Reputation updated to: {chosen_seller.reputation_score:.2f}\")\n",
        "\n",
        "    print(\"\\n--- Simulation Ended ---\")\n",
        "\n",
        "    print(\"\\nFinal Seller States:\")\n",
        "    for seller in sellers:\n",
        "        print(f\"  {seller}\")\n",
        "\n",
        "    print(\"\\nFinal Buyer Q-Tables (after {num_rounds} rounds):\")\n",
        "    for buyer in buyers:\n",
        "        print(f\"  {buyer.name}: {buyer.q_table}\")\n",
        "\n",
        "# --- Run the Simulation ---\n",
        "if __name__ == \"__main__\":\n",
        "    run_marketplace_simulation()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d83g3SPAWMV",
        "outputId": "25dc310a-893b-4afd-b00d-169cdd770079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing Multi-Agent Marketplace Simulation ---\n",
            "\n",
            "Initial Seller States:\n",
            "  Seller(name=Seller A, price=50.0, fraud=False, rep=0.50)\n",
            "  Seller(name=Seller B, price=30.0, fraud=True, rep=0.50)\n",
            "\n",
            "Initial Buyer Q-Tables (before any transactions):\n",
            "  Buyer X: {}\n",
            "  Buyer Y: {}\n",
            "\n",
            "--- Starting Simulation for 6 Rounds ---\n",
            "\n",
            "--- Round 1 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploiting) Chose seller: Seller A (Q-value: 0.00)\n",
            "  [Buyer X] Transaction with Seller A: Fraud=False, Price=50.0, Rep=0.50\n",
            "  [Buyer X] Calculated reward: 0.52\n",
            "  [Buyer X] Updated Q-value for choosing Seller A: 0.05\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploiting) Chose seller: Seller A (Q-value: 0.00)\n",
            "  [Buyer Y] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer Y] Calculated reward: 1.02\n",
            "  [Buyer Y] Updated Q-value for choosing Seller A: 0.10\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "--- Round 2 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploiting) Chose seller: Seller A (Q-value: 0.05)\n",
            "  [Buyer X] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer X] Calculated reward: 1.02\n",
            "  [Buyer X] Updated Q-value for choosing Seller A: 0.15\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploring) Chose seller: Seller B\n",
            "  [Buyer Y] Transaction with Seller B: Fraud=True, Price=30.0, Rep=0.50\n",
            "  [Buyer Y] Calculated reward: -10.00\n",
            "  [Buyer Y] Updated Q-value for choosing Seller B: -0.99\n",
            "  [Seller B] Reputation updated to: 0.00\n",
            "\n",
            "--- Round 3 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploring) Chose seller: Seller B\n",
            "  [Buyer X] Transaction with Seller B: Fraud=True, Price=30.0, Rep=0.00\n",
            "  [Buyer X] Calculated reward: -10.00\n",
            "  [Buyer X] Updated Q-value for choosing Seller B: -0.99\n",
            "  [Seller B] Reputation updated to: 0.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploiting) Chose seller: Seller A (Q-value: 0.10)\n",
            "  [Buyer Y] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer Y] Calculated reward: 1.02\n",
            "  [Buyer Y] Updated Q-value for choosing Seller A: 0.20\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "--- Round 4 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploiting) Chose seller: Seller A (Q-value: 0.15)\n",
            "  [Buyer X] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer X] Calculated reward: 1.02\n",
            "  [Buyer X] Updated Q-value for choosing Seller A: 0.25\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploiting) Chose seller: Seller A (Q-value: 0.20)\n",
            "  [Buyer Y] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer Y] Calculated reward: 1.02\n",
            "  [Buyer Y] Updated Q-value for choosing Seller A: 0.30\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "--- Round 5 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploiting) Chose seller: Seller A (Q-value: 0.25)\n",
            "  [Buyer X] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer X] Calculated reward: 1.02\n",
            "  [Buyer X] Updated Q-value for choosing Seller A: 0.35\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploiting) Chose seller: Seller A (Q-value: 0.30)\n",
            "  [Buyer Y] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer Y] Calculated reward: 1.02\n",
            "  [Buyer Y] Updated Q-value for choosing Seller A: 0.40\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "--- Round 6 ---\n",
            "\n",
            "Buyer X's turn:\n",
            "  [Buyer X] (Exploiting) Chose seller: Seller A (Q-value: 0.35)\n",
            "  [Buyer X] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer X] Calculated reward: 1.02\n",
            "  [Buyer X] Updated Q-value for choosing Seller A: 0.45\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "Buyer Y's turn:\n",
            "  [Buyer Y] (Exploiting) Chose seller: Seller A (Q-value: 0.40)\n",
            "  [Buyer Y] Transaction with Seller A: Fraud=False, Price=50.0, Rep=1.00\n",
            "  [Buyer Y] Calculated reward: 1.02\n",
            "  [Buyer Y] Updated Q-value for choosing Seller A: 0.50\n",
            "  [Seller A] Reputation updated to: 1.00\n",
            "\n",
            "--- Simulation Ended ---\n",
            "\n",
            "Final Seller States:\n",
            "  Seller(name=Seller A, price=50.0, fraud=False, rep=1.00)\n",
            "  Seller(name=Seller B, price=30.0, fraud=True, rep=0.00)\n",
            "\n",
            "Final Buyer Q-Tables (after {num_rounds} rounds):\n",
            "  Buyer X: {'default_state': {'Seller A': 0.45167949463725493, 'Seller B': -0.9861938235294118}}\n",
            "  Buyer Y: {'default_state': {'Seller A': 0.49970929513725487, 'Seller B': -0.9908235294117648}}\n",
            "\n",
            "--- Analysis ---\n",
            "\n",
            "1. How learning influences the strategies of the buyer agents:\n",
            "   - Initially, buyers might choose sellers randomly (exploration).\n",
            "   - After interacting with Seller B (fraudulent), buyers receive a large negative reward (-10.0).\n",
            "   - This negative reward significantly lowers the Q-value associated with choosing Seller B in the buyer's Q-table.\n",
            "   - Over time, as the simulation runs, buyers learn that choosing Seller B leads to poor outcomes.\n",
            "   - Consequently, the probability of choosing Seller B decreases (due to lower Q-value), and buyers prefer Seller A.\n",
            "   - The learning rate and discount factor control how quickly the Q-values adapt to new information.\n",
            "\n",
            "2. How trust/reputation prevents buyers from choosing fraudulent sellers:\n",
            "   - In this simulation, reputation is implicitly used in the reward calculation.\n",
            "   - The reward function considers the seller's current reputation score: `reward = normalized_price_reward + normalized_reputation_reward`.\n",
            "   - When a buyer interacts with Seller B (fraudulent), the transaction outcome is negative, leading to a reward of -10.0.\n",
            "   - This negative outcome also results in a 0 feedback score, which significantly lowers Seller B's reputation over time.\n",
            "   - As Seller B's reputation drops, its contribution to any positive reward calculation decreases.\n",
            "   - Even if the price is lower, the low reputation makes the overall expected reward for choosing Seller B very negative.\n",
            "   - This mechanism discourages future buyers (or the same buyer learning) from selecting sellers with low reputations,\n",
            "     effectively filtering out potentially fraudulent agents from the marketplace.\n"
          ]
        }
      ]
    }
  ]
}